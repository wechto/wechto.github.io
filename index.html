<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 80px;
      height: 80px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 100px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Jinxin</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Jinxin Liu</name>
              </p>
              <p>
                I am currently a joint Ph.D. student of Zhejiang University and Westlake University, advised by Dr.
                Donglin Wang. Also, I am a member of <a href="https://milab.westlake.edu.cn/">Machine Intelligence
                  Laboratory (MiLAB)</a> in Westlake University, where I do my research work on deep reinforcement
                learning and robot learning. Before coming to Westlake University, I obtained my bachelor's degree of
                Engineering from Chongqing University of Posts and Telecommunications, majoring in Communication
                Engineering.
              </p>

              <p>
                My main research goal is to develop algorithms which enable robotic systems to learn how to perform
                complex tasks in a variety of unstructured environments. To that end, I work towards building deep
                reinforcement learning algorithms that can learn in the real world. Recently, I have been specifically
                focusing on the problems of 1) unsupervised reinforcement learning, 2) transition dynamics adaptation,
                3) offline reinforcement learning for quadruped robots in real world.
              </p>

              <p align=center>
                <a href="mailto:liujinxin@westlake.edu.cn">Email</a> &nbsp/&nbsp
                <a href="files/cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/liuinn"> GitHub </a> &nbsp/&nbsp
                <a
                  href="https://scholar.google.com/citations?hl=en&user=oC16lJ0AAAAJ&view_op=list_works&sortby=pubdate">Google
                  Scholar</a> &nbsp;
              </p>
            </td>
            <td width="40%">
              <img src="images/ta1.jpg" width="200">
            </td>
          </tr>
        </table>

        <br>
        <br>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr>

            <td width="15%">
              <div class="one">
                <img src='images/dara.png' width=130%>
              </div>
            </td>
            <td valign="top" width="85%">
              <p><a href="https://openreview.net/forum?id=9SDQB3b68K">
                  <papertitle>DARA: Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning
                  </papertitle>
                </a><br><u>Jinxin Liu</u>, Hongyin Zhang, DonglinWang<br>
                <em>ICLR 2022</em><br>
                <a href="https://openreview.net/pdf?id=9SDQB3b68K">paper</a>
                &nbsp;
                </a>
              </p>
            </td>
          </tr>


          <td width="15%">
            <div class="one">
              <img src='images/gpim.png' width=130%>
            </div>
          </td>
          <td valign="top" width="85%">
            <p><a href="https://arxiv.org/pdf/2104.05043.pdf">
                <papertitle>Learn Goal-Conditioned Policy with Intrinsic Motivation for Deep Reinforcement Learning
                </papertitle>
              </a><br><u>Jinxin Liu</u>, Donglin Wang, Qiangxing Tian, Zhengyu Chen<br>
              <em>AAAI 2022</em><br>
              <a href="https://arxiv.org/pdf/2104.05043.pdf">paper</a>
              &nbsp;
              <!--<a href ="https://sites.google.com/view/gpim/">homepage</a>-->
              </a>
            </p>
          </td>
    </tr>

    <td width="15%">
      <div class="one">
        <img src='images/dars.png' width=130%>
      </div>
    </td>
    <td valign="top" width="85%">
      <p><a href="https://arxiv.org/pdf/2110.12997.pdf">
          <papertitle>Unsupervised Domain Adaptation with Dynamics Aware Rewards in Reinforcement Learning
          </papertitle>
        </a><br><u>Jinxin Liu</u>, Hao Shen, Donglin Wang, Yachen Kang, Qiangxing Tian<br>
        <em>NeurIPS 2021</em><br>
        <a href="https://arxiv.org/pdf/2110.12997.pdf">paper</a>
        &nbsp;
        <!--<a href ="https://sites.google.com/view/milab-dars/">homepage</a>-->
        </a>
      </p>
    </td>
    </tr>


    <td width="15%">
      <div class="one">
        <img src='images/ist.png' width=130%>
      </div>
    </td>
    <td valign="top" width="85%">
      <p><a href="https://www.ijcai.org/proceedings/2020/0401.pdf">
          <papertitle>Independent Skill Transfer for Deep Reinforcement Learning
          </papertitle>
        </a><br>Qiangxing Tian, Guanchu Wang, <u>Jinxin Liu</u>, Donglin Wang, Yachen Kang
        <br>
        <em>IJCAI 2020</em><br>
        <a href="https://www.ijcai.org/proceedings/2020/0401.pdf">paper</a>
        &nbsp;
        </a>
      </p>
    </td>
    </tr>




  </table>

  </td>
  </tr>
  </table>

  <table width="100%" align="right" border="0" cellspacing="0" cellpadding="20">
    <p align="right">
      <font size="2">
        <!-- Start of WebFreeCounter Code -->
        <a href="http://www.statworker.com/" target="_blank"><img
            src="https://www.webfreecounter.com/hit.php?id=gvepcapk&nd=6&style=1" border="0" alt="statworker"></a>
        <!-- End of WebFreeCounter Code -->
      </font>
    </p>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td>
        <br>
        <p align="right">
          <font size="2">
            Website template from <a href="https://abhishekunique.github.io/">Abhishek Gupta</a>.
            <br>
            Last updated March 2022.
          </font>
        </p>
      </td>
    </tr>
  </table>


</body>

</html>